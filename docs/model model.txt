#euclidean distance


Activation Functions
leaky relu? better than sigmoid

sigmoid
linear
tanh


Loss Functions
mse
L2

Optimizer 
Adam, amsgrad = True
